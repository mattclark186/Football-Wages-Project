{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b9d014-73a0-40d3-a27e-b4aea66c1581",
   "metadata": {},
   "source": [
    "# Football Wages Web Scraping 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69302215-ef6b-4902-89f1-62f06c80ae4f",
   "metadata": {},
   "source": [
    "This scrapes the web for football wage data. It loops through the urls for the top 5 leagues, within each url it loops through the last 10 full seasons (14/15 - 23/24). It saves the data as CSVs in the relevant folder for each league."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de26474-3500-4f29-8522-e8fbf3316632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32c41535-27fb-43e4-a4d7-995df241acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#different urls for each league\n",
    "PL = \"https://fbref.com/en/comps/9/wages/Premier-League-Wages\"      #premier league\n",
    "SA = \"https://fbref.com/en/comps/11/wages/Serie-A-Wages\"            #serie a\n",
    "LL = \"https://fbref.com/en/comps/12/wages/La-Liga-Wages\"            #la liga\n",
    "BL = \"https://fbref.com/en/comps/20/wages/Bundesliga-Wages\"         #bundesliga\n",
    "LU = \"https://fbref.com/en/comps/13/wages/Ligue-1-Wages\"            #ligue 1\n",
    "urls = [PL, SA, LL, BL, LU]\n",
    "leagues = ['PL','SA','LL','BL','LU']\n",
    "seasons = ['23-24','22-23','21-22','20-21','19-20','18-19','17-18','16-17','15-16','14-15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e303b483-95e0-4d4c-93df-6c0a82232b53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(urls)):\n",
    "    url = urls[i]                    #loop throuh each league using their urls\n",
    "\n",
    "    #opens the url with the chrome web driver\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    #rejects all cookies when page opens up\n",
    "    no_cookies = driver.find_element(By.XPATH, \"//button[@class=' osano-cm-denyAll osano-cm-buttons__button osano-cm-button osano-cm-button--type_denyAll ']\")\n",
    "    no_cookies.click()\n",
    "\n",
    "    #waits 1 second to allow page to load\n",
    "    time.sleep(1)\n",
    "\n",
    "    for j in range(len(seasons)):\n",
    "        \n",
    "        #clicks previous season button to go back to previous season\n",
    "        prev_season = driver.find_element(By.XPATH, \"//a[@class='button2 prev']\")\n",
    "        prev_season.click()\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        if j == 3:\n",
    "            popup_close = driver.find_element(By.XPATH, \"//div[@id='modal-close']\")    #closes pop-up that appears\n",
    "            popup_close.click()\n",
    "            time.sleep(1)\n",
    "\n",
    "        #defines 'soup' as the pages html and 'table' as the specific html for the table of data\n",
    "        soup = bs(driver.page_source, \"html.parser\")\n",
    "        table = soup.find(\"table\", {\"id\": \"squad_wages\"})\n",
    "\n",
    "        #pulls the table headers from the html\n",
    "        table_titles = table.find_all(\"th\", {\"scope\": \"col\"})\n",
    "        titles = [title.text.strip() for title in table_titles]\n",
    "\n",
    "        #creates a data frame with the table headers\n",
    "        df = pd.DataFrame(columns = titles)\n",
    "\n",
    "        all_data = []\n",
    "\n",
    "        for t in table:\n",
    "            rows = table.find(\"tbody\").find_all(\"tr\")           #finds the rows of data using the tags 'tbody' and 'tr'\n",
    "            for row in rows:\n",
    "                cols = row.find_all([\"th\",\"td\"])                #finds the individual data using the tags 'th' and 'td'\n",
    "                cols = [col.text.strip() for col in cols]       #cleans the data using strip()\n",
    "                all_data.append(cols)\n",
    "                length = len(df)                                #adds the data to the dataframe\n",
    "                df.loc[length] = cols\n",
    "\n",
    "\n",
    "        #deletes duplicate rows\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        #saves file as league + season in that leagues folder e.g. for the first one 'PL 23-24.csv' in the PL folder within the Football Wages folder.\n",
    "        folder = r\"C:\\Users\\mattc\\OneDrive\\Documents\\Data\\Football Wages\\\\\" + leagues[i] + \"\\\\\"\n",
    "        filename = leagues[i] + \" \" + seasons[j] + \".csv\"\n",
    "        df.to_csv(folder + filename, index=False)\n",
    "\n",
    "\n",
    "#closes the web driver browser\n",
    "driver.quit()\n",
    "driver = None\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da67871e-0952-4358-8e80-e80e20d43dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
